---
title: "Untitled"
author: "Jonathan Bourne"
date: "20 January 2016"
output: html_document
---

Setup packages and install packages

Current Priority: Impute the features on the test set
The neural net lists are under construction but they won't work properly if the data in the test set isn't imputed, this needs to be done as it will probably take a long time.

```{r}
packages <- c("randomForest","dplyr", "ggplot2", "caret", "Amelia", "tidyr","pROC", "parallel", "e1071","adabag", "ipred") #, "Zelig", "doMC") #If amelia is used Betadist and mi can be removed

sapply(packages, install.packages)

sapply(packages, library, character.only = TRUE)
select <- dplyr::select #Clash between dplyr and MASS which is loaded by Caret
setwd("~/Dropbox/MajoR/Data")
# basewd <- "C:/Users/Jonno/Dropbox/MajoR/Data"
# setwd(basewd)

load("data.Rdata")
load("FullImputTrain.Rdata")
#data.raw<- read.csv("train.csv")
#test <- read.csv("test_2.csv")
#data <- data.raw

```

MAE function allows evaluation of the models
```{r}
MAE <- function(data1, data2){
      abs(data1-data2) %>% mean
}
```


Time series function
```{r}

timestats <- function(data){

#Geometric mean has almost perfect correlation with mean and so won't add anything  
#   #Takes a time series stored as rows in a dataframe, without Na values and extracts Mean,median, max,min var, geomettric mean, and returns a data frame. 
# gm_mean <- function(x, na.rm=TRUE){
#   exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
# } #http://stackoverflow.com/questions/2602583/geometric-mean-is-there-a-built-in

rowVars <- function(x) {
  rowSums((x - rowMeans(x))^2)/(dim(x)[2] - 1)
} #http://stackoverflow.com/questions/25099825/row-wise-variance-of-a-matrix-in-r

#this function has such inconsistant syntax because I am trying to take the fastes functions possible to operate on the dataset
x <- cbind(rowMeans(data),
           rowVars(data),
           apply(data, 1 ,median),
           do.call(pmin, data), 
           do.call(pmax, data)#,
#           apply(data+1, 1,gm_mean)-1,
#           rowSums(data) #there is almost perfect corelllation between these two and mean
           ) %>% data.frame

names(x) <- c("means", "vars","median","mins", "max") #, "gm_mean", "sums" )
x
}




```

Imputation function
```{r}

imputer <-function(data,imputations =5, number_cols = 119,stockspergroup = 100, ncpus = 1  )  {
    #The key is to extract the imputations of each group and insert them into a reconstructed table so that there isn't a build up of a massive list of Amelia objects as this causes the computer to crash. The downside is that there is a loss of information that can be used to analyse the fit of the imputations. In addition the datatime dataframe is made in batches to avoid causing the system to crash when it is transposing the matrix.
    
    group_size <- number_cols*stockspergroup
    number_groups <- number_cols*nrow(data)/group_size
    
    # create a list of dataframes that are used to reconstruct the imputed data
    reconstr <- matrix(NA, nrow = nrow(data), ncol =(number_cols+1)) %>% data.frame
    names(reconstr) <- c(names(select(data, Ret_2:Ret_120)),"alphaordering")
    reconstrList <- replicate(imputations, reconstr, simplify=FALSE)
    
    set.seed(1928)
    for (n in 1:number_groups) {
      print(paste(n,"of",number_groups))
      #identify row numbers in final dataframe and insert the data into the rows
      rowids <- (((n-1)*stockspergroup)+1):(n*stockspergroup)
    #reformat for time series imputations
    datatime <- data[rowids,] %>% select(Ret_2:Ret_120) %>% t %>% data.frame %>% 
      mutate(timeID = 1:number_cols) %>% gather(., key = Id, value = ROI, -timeID ) 
      
      #imput select time series m times
      a.out <- datatime %>% amelia(., ts="timeID", 
                                                  cs = "Id", 
                                          polytime = 2, intercs = TRUE, 
                                          m= imputations,
                                          empri = group_size*0.05,
                                          parallel="snow",
                                         ncpus = ncpus)
      
      
      for ( i in 1:imputations) {
        tempId <-a.out$imputations[[i]] %>% 
                  spread(., key = Id, value = ROI) %>% select(-timeID) %>% t
        reconstrList[[i]][rowids,1:number_cols] <- tempId
        reconstrList[[i]]$alphaordering[rowids] <- rownames(tempId) %>% sub("X","",.) %>%
          as.numeric
      }
    }

    reconstrList <- lapply(reconstrList, function(n){
      n %>% arrange(alphaordering) %>% select(-alphaordering)
    })
    reconstrList
}

```


Find columns to remove
```{r}
lowvar <-nearZeroVar(data[1:28]) #these are the same so can be removed from the datasets column 17 is constant

NASdata <- sapply( data[,1:28], function(n) sum(is.na(n)))

highNAS <-which(NASdata/nrow(data) >0.2) #returns index of major missing elements

#removes the junk variables
data2 <- data[,-c(lowvar, highNAS,29:211)] %>% mutate(Id = paste("X",Id, sep=""))
```


Imputation code chunk, takes the relvant variables, and first imputs the time series, creates a summary statistics of the time series. After recombining the imputed data set an new variables, the features are then imputed. the resulting number of imputations is timeimput*featureimput

```{r}
timeimput <-5
featureimput <- 5
number_cols <- 119
stockspergroup <- 20


data.raw <- data
data <- data.raw[1025:1124,]
imputations <- 5

#should be run on a c4.xlarge which has 4 cores
#create a list of the imputed time series and the unimputed feature set
#ImputedTrainTime <- imputer(data, imputations =5, number_cols ,stockspergroup, ncpus = 4 )
#testImput <- imputer(data = test, imputations =5, number_cols ,stockspergroup, ncpus = 4  )

#Test the imputer function
#Imputtest <- imputer(data, imputations =timeimput, number_cols ,stockspergroup=stockspergroup )


x <-rowSums(ImputedTrainTime[[3]] == select(data, Ret_2:Ret_120), na.rm=TRUE) #This checks to see is there are most matches, if there are lots of zeros it's a problem


#Create the time series summary statistics and combine with the unimputed feature set
datlist <- lapply(ImputedTrainTime,function(n){
  x <- timestats(n)
  bind_cols(data2, x) # [,-c(30:31)] #does the geometric mean and sum need to be removed?
    }
  )


#Impute the feature set using the Intraday summary statistics
datlist2 <- vector("list", featureimput*timeimput)
for (n in 1:featureimput)  {
  print(paste(n, "of",featureimput) )
   a.out <-amelia(datlist[[n]],idvars = "Id",
                   m = featureimput, empri = nrow(datlist[[n]]), 
                   parallel = "snow", ncpus = detectCores())
        for ( i in 1:5){
          datlist2[[(n-1)*5+i]] <-   a.out$imputations[[i]]
    }
}



#Create the time series summary statistics and combine with the unimputed feature set
testdatlist <- lapply(testImput,function(n){
  x <- timestats(n)
  bind_cols(data2, x) # [,-c(30:31)] #does the geometric mean and sum need to be removed?
    }
  )


#Impute the feature set using the Intraday summary statistics
testdatlist2 <- vector("list", featureimput*timeimput)
for (n in 1:featureimput)  {
  print(paste(n, "of",featureimput) )
   a.out <-amelia(testdatlist[[n]],idvars = "Id",
                   m = featureimput, empri = nrow(testdatlist[[n]]), 
                   parallel = "snow", ncpus = detectCores())
        for ( i in 1:5){
          testdatlist2[[(n-1)*5+i]] <-   a.out$imputations[[i]]
    }
}


```


basic model parameters
```{r}


maeSummary <- function (data,
                        lev = NULL,
                        model = NULL) {
   out <- -mean(abs(data$obs - data$pred)) 
   names(out) <- "MAE"
   out
}

train_control <- trainControl(method="cv", number=5, summaryFunction = maeSummary)

set.seed(1928)
trainIndex <- createDataPartition(1:nrow(data), p=.7, list = FALSE)
responseOneTrain <- data$Ret_PlusOne[trainIndex]
MedTrainPos <-median(responseOneTrain[responseOneTrain >0])
MedTrainNeg <-median(responseOneTrain[responseOneTrain <0])

datlength <- length(datlist2)

RegNNlistPlusOne <- vector("list", datlength )


```

base line predictive power on Plus 1
```{r}
#Calculate RMSE for 0, the RMSE is 0.01575095
zero <- MAE(rep(0,nrow(data)), data$Ret_PlusOne)

#Calculate RMSE using median, slightly better than using 0 result 0.01555366
medval <- rep(median(responseOneTrain), length(data$Ret_PlusOne[-trainIndex]))
MAE(medval,data$Ret_PlusOne[-trainIndex])

#Calculate RMSE for predicting the sign and putting in the median value RMSE it is better than zero prediction 0.01084563
signmeds<- rep(NA, length(data[-trainIndex,]))
signmeds <-ifelse(data$Ret_PlusOne[-trainIndex] >0,MedTrainPos,MedTrainNeg)
MAE(signmeds, data$Ret_PlusOne[-trainIndex])

#at what percentage of correct classification and put in median is performanc better than guessing? aka how good does the classifier need to be?
#this code missclassfies a percentage of the validation set and applies the training median for positive and negative. The process is repeated n times to get the average and varience

responseOneTest <- data$Ret_PlusOne[-trainIndex]
guessright <- rep(NA, length(responseOneTest))
guessright <-ifelse(responseOneTest >0, 1, 0)

set.seed(12)
z <- sapply(seq(0.5,to = 1, by = .05), function(n){
    x <- rep(NA, 30)
      for (i in 1:30){
        Indright <- sample(1:length(guessright), ceiling(n*length(guessright))  )
        testvect <- guessright
        testvect[-Indright] <- ifelse(testvect[-Indright] == 1, 0,1)
        testsignmeds<- rep(NA, length(responseOneTest))
        testsignmeds <-ifelse(testvect >0,MedTrainPos,MedTrainNeg)
        x[i] <- MAE(testsignmeds, data$Ret_PlusOne[-trainIndex])
      }
    x
  }
)

# At 70% correct identification it is better to classify than use 0. The Improvement is linear
rbind(seq(0.5,to = 1, by = .05), colMeans(z)) %>% t %>% plot

#the varience is very small
boxplot(z)
abline(a =zero[1], b = 0)
#can aggregating multiple classifiers produce this level of accuracy?

```


Base line predictive power on timeseries, unless you can predict the frequency there is almost no way to beat 0
```{r}

timegold <- data[,148:207] %>%  t %>% as.vector

# error on zero prediction on the time series, it is very small 0.0006331534
m <- matrix(0, nrow = nrow(data), ncol = 60) %>% t %>% as.vector
MAE(m, timegold)

# error on using true target timeseries average, it is baiscally the same as 0 0.0006331533
m <- matrix(median(timegold), nrow = nrow(data), ncol = 60) %>% t %>% as.vector
MAE(m, timegold)

# error on using true target row timeseries average, it is marginally better as 0.0006290278
rowmeds <- apply(data[,148:207],1,median) %>% rep( each = 60)
MAE(rowmeds, timegold)


# error on using the known target row timeseries average, it is worse than zero as 0.0006381682
rowmeds <-  sapply(ImputedTrainTime, function(n) {
              apply(n,1,median)
    }
  ) %>% apply(.,1,median) %>% rep( each = 60)

MAE(rowmeds, timegold)

```


This chunk tunes an averaged neural networks parameters, once and appropriate area is found a list of networks will be made across the data sets and aggregated to try and get a predictive power above 70%
```{r}

nnetGrid <- expand.grid(.decay=c(0, 0.01, 0.1),
                        .size = c(1:10), .bag = FALSE)

#this model indicates that the model stabilises on a wieght decay of 0.1 and 10 units
nnetTuneGridcat1 <- train(x = datlist2[[1]][trainIndex,-1],
                  y = PosNegcat[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)


#this model makes a repeats the grid search for a classification neural net using more units and a smaller decay range as the previous model was at the extreme of the grid when the model started stabilising.
nnetGrid <- expand.grid(.decay=c(0.05, 0.1, 0.15),
                        .size = c(9:14), .bag = FALSE)

#removal of high corellation variables added in to reduce colineararity problems
highcor <- findCorrelation(cor(datlist2[[1]][trainIndex,-1]), cutoff = 0.75) +1

i <- 1 # remove before putting in a loop
set.seed(28)
nnetTuneGridcat2 <- train(x = datlist2[[i]][trainIndex,highcor],
                  y = PosNegcat[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)

#this model makes a repeats the grid search for a classification neural, the model was still at the extreme end of the decay range so I have increased it to see if I get any more improvements out
nnetGrid <- expand.grid(.decay=c(0.15, .5, 1),
                        .size = c(9:13), .bag = FALSE)

#removal of high corellation variables added in to reduce colineararity problems
highcor <- findCorrelation(cor(datlist2[[1]][trainIndex,-1]), cutoff = 0.75) +1

i <- 1 # remove before putting in a loop
set.seed(28)
nnetTuneGridcat3 <- train(x = datlist2[[i]][trainIndex,highcor],
                  y = PosNegcat[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)

nnetGrid <- expand.grid(.decay=c(1, 3, 5),
                        .size = c(7:10), .bag = FALSE)


#removal of high corellation variables added in to reduce colineararity problems
highcor <- findCorrelation(cor(datlist2[[1]][trainIndex,-1]), cutoff = 0.75) +1

i <- 1 # remove before putting in a loop
set.seed(28)
nnetTuneGridcat4 <- train(x = datlist2[[i]][trainIndex,highcor],
                  y = PosNegcat[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)


nnetGrid <- expand.grid(.decay=c(2, 3, 4),
                        .size = c(5:8), .bag = FALSE)


#removal of high corellation variables added in to reduce colineararity problems
highcor <- findCorrelation(cor(datlist2[[1]][trainIndex,-1]), cutoff = 0.75) +1

i <- 1 # remove before putting in a loop
set.seed(28)
nnetTuneGridcat5 <- train(x = datlist2[[i]][trainIndex,highcor],
                  y = PosNegcat[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)



```


This chunk tunes a Regression Neural net, once done a list of neural nets can then be made using the setting from the tuned net. Ideally the net would be tuned on all the imputed models and then averaged, but that woud take for ever
```{r}

nnetGrid <- expand.grid(.decay=c(0.01, 0.05, 0.1),
                        .size = c(6:10), .bag = FALSE)

train_control <- trainControl(method="cv", number=5, summaryFunction = maeSummary)

#prevent corellations between nets by removing highly correllated features
highcor <- findCorrelation(cor(datlist2[[1]][trainIndex,-1]), cutoff = 0.75) +1


i <-1 # remove when putting in a loop
#This model uses an averaged neural net to regress return
nnetTuneGridReg1 <- train(x = datlist2[[i]][trainIndex,-c(1, highcor)],
                  y = data$Ret_PlusOne[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  #metric = "MAE",
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)



nnetGrid <- expand.grid(.decay=c(0.05, 0.1, 0.5),
                        .size = c(2:8), .bag = FALSE)

train_control <- trainControl(method="cv", number=5, summaryFunction = maeSummary)

#prevent corellations between nets by removing highly correllated features
highcor <- findCorrelation(cor(datlist2[[1]][trainIndex,-1]), cutoff = 0.75) +1


i <-1 # remove when putting in a loop
#This model uses an averaged neural net to regress return
nnetTuneGridReg2 <- train(x = datlist2[[i]][trainIndex,-c(1, highcor)],
                  y = data$Ret_PlusOne[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  #metric = "MAE",
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[i]][trainIndex,-1])+1) +10 +1,
                  maxit =500)


# create a prediction matrix

predmat <- sapply(1:length(RegNNlistPlusOne), function(i){
    predict(RegNNlistPlusOne[[i]], datlist2[[i]][-trainIndex,])
})  

predmat <- cbind(predmat, rowMeans(predmat))


#mi.meld may be of interest here

#Ideally all the individual models will have similar results but the averaged one will have significantly better results
modelcomps <- sapply(1:ncol(predmat), function(n) {
    postResample(predmat[,n], data$Ret_PlusOne[-trainIndex])
  }
)

postResample(predmat[,26], data$Ret_PlusOne[-trainIndex])

#Calculates RMSE for a regression model
postResample(predict(nnetTuneGridReg2, datlist2[[1]][-trainIndex,]), data$Ret_PlusOne[-trainIndex])



```


make a list of models to predict plus 1 and plus 2
```{r}


RegNNlistPlusOne <- vector("list", datlength)

train_control <- trainControl(method="cv", number=5, summaryFunction = maeSummary)
datlength <- length(datlist2)
nnetGrid <- expand.grid(.decay=c(0.01),
                        .size = c(5:7), .bag = TRUE)


for (n in 1:datlength){
  print(paste("Regress", n, "of", datlength))
    RegNNlistPlusOne[[n]] <- train(x = datlist2[[n]][trainIndex,-c(1, highcor)],
                  y = data$Ret_PlusOne[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  metric = "MAE",
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[n]][trainIndex,-1])+1) +10 +1,
                  maxit =500)
}


nnetGrid <- expand.grid(.decay=c(0.01),
                        .size = c(5:7), .bag = TRUE)

RegNNlistPlusTwo <- vector("list", datlength)

for (n in 1:datlength){
  print(paste("Regress", n, "of", datlength))
    RegNNlistPlusTwo[[n]] <- train(x = datlist2[[n]][trainIndex,-c(1, highcor)],
                  y = data$Ret_PlusTwo[trainIndex],
                  method = "avNNet",
                  tuneGrid = nnetGrid,
                  trControl = train_control,
                  metric = "MAE",
                  preProc = c("center", "scale"),
                  lineout = TRUE,
                  trace =TRUE,
                  MaxNWts =  10*(ncol(datlist2[[n]][trainIndex,-1])+1) +10 +1,
                  maxit =500)
}

setwd("~/Dropbox/MajoR/Data/PlusOneList")
sapply(1:length(RegNNlistPlusOne), function(n){
        save(RegNNlistPlusOne[[n]], file = paste("RegNNlistPlusOne",n,"Rdata"))
        }
)
```


test bagging
```{r}
    

train_control <- trainControl(method="cv", number=5, summaryFunction = maeSummary)
trbag  <- train(x = datlist2[[1]][trainIndex,-1],
                         y = data$Ret_PlusOne[trainIndex],  
                              method = "treebag",
                              nbagg = 50,
                          metric = "MAE"  ,  
                          trControl = train_control)
x <- predict(trbag, data[-trainIndex,])

```


create plus one and two bounds this chunk is not very useful
```{r}
standarddevsPlusOne <- sd(data$Ret_PlusOne)*1
meanPlusOne <- mean(data$Ret_PlusOne)
lowerboundone <- meanPlusOne-standarddevsPlusOne
upperboundone <- meanPlusOne+standarddevsPlusOne

PlusOnecat <- rep(0, 40000)
PlusOnecat[data$Ret_PlusOne <lowerboundone] <- -1
PlusOnecat[data$Ret_PlusOne >upperboundone] <- 1



PlusOnecatEx <- rep(0, 40000)
PlusOnecatEx[data$Ret_PlusOne <lowerboundone] <- -1
PlusOnecatEx[data$Ret_PlusOne >upperboundone] <- 1


PosNegcat <- rep(0, 40000)
PosNegcat[data$Ret_PlusOne >0] <- 1
PosNegcat <- as.factor(PosNegcat)


PosNegcat2 <- rep(0, 40000)
PosNegcat2[data$Ret_PlusTwo >0] <- 1
PosNegcat2 <- as.factor(PosNegcat2)

standarddevsPlusTwo <- stdev(data$Ret_PlusTwo)*3
meanPlusTwo <- mean(data$Ret_PlusTwo)
lowerboundTwo <- meanPlusTwo-standarddevsPlusTwo
upperboundTwo <- meanPlusTwo+standarddevsPlusTwo

PlusTwocat <- rep(0, 40000)
PlusTwocat[data$Ret_PlusTwo <lowerboundTwo] <- -1
PlusTwocat[data$Ret_PlusTwo >upperboundTwo] <- 1


```


Predict Positive negative day +1
```{r}

PosNegcat <- rep(0, 40000)
PosNegcat[data$Ret_PlusOne >0] <- 1
PosNegcat <- as.factor(PosNegcat)

train_control_fac <- trainControl(method="cv", 
                              number=5, 
                              verboseIter = TRUE,
                              classProbs = TRUE)


classPosNegtrb <- train(x = datlist2[[1]][trainIndex,-1],
                        y = make.names(PosNegcat[trainIndex]),  
                        method = "treebag",
                        nbagg = 50,
                        trControl = train_control_fac)
save(classPosNegtrb, file="classPosNegtrb.Rdata")

c50Grid <- expand.grid(.trials = c(1:9, (1:10)*10),
                       .model = c("tree", "rules"),
                       .winnow = c(TRUE, FALSE))

classPosNegC5 <- train(x = datlist2[[1]][trainIndex,-1],
                  y = make.names(PosNegcat[trainIndex]),  
                  method = "C5.0",
                  tuneGrid = c50Grid,
                  trControl = train_control_fac,
                  preProc = c("center", "scale"))  
save(classPosNegC5, file="classPosNegC5.Rdata")


classPosNegKnn <- train(x = datlist2[[1]][trainIndex,-1],
                  y = make.names(PosNegcat[trainIndex]),  
                  method = "knn",
                  trControl = train_control_fac,
                  preProc = c("center", "scale"))  
save(classPosNegKnn, file="classPosNegKnn.Rdata")

nnetGrid <- expand.grid(.decay=c(0.01),
                        .size = c(5:7), .bag = TRUE)

classPosNegnn <- train(x = datlist2[[1]][trainIndex,-1],
                       y = make.names(PosNegcat[trainIndex]),  
                    method = "avNNet",
                    tuneGrid = nnetGrid,
                    trControl = train_control_fac,
                    preProc = c("center", "scale"),
                    trace =TRUE,
                    MaxNWts =  10*(ncol(datlist2[[1]][trainIndex,-1])+1) +10 +1,
                    maxit =500)
save(classPosNegnn, file="classPosNegnn.Rdata")


predsPosNeg <- predict(classPosNegC5, datlist2[[1]][-trainIndex,])
confPosNeg <- confusionMatrix(predsPosNeg, make.names(PosNegcat[-trainIndex]))

predsPosNegmat <- sapply(1:25, function(n){
              predict(classPosNegC5, datlist2[[n]][-trainIndex,])
          }
      )

cutoff <- sapply(1:25, function(n)
  ifelse(rowSums(predsPosNegmat =="X1") >n,"X1","X0") 
  )

AggAcc <- sapply(1:24, function(i) {
      confusionMatrix(cutoff[,i], make.names(PosNegcat[-trainIndex]))$overall[1]
    }
  )
```


Predict Positive negative day +2
```{r}
classPosNeg2 <- train(x = data3,y = PosNegcat2,  
                    method = "treebag",
                    nbagg = 50,
                    metric = "ROC",
                    trControl = ctrl)

predsPosNeg2 <- predict(classPosNeg2, data3)
confPosNeg2 <- confusionMatrix(predsPosNeg2, PosNegcat2)

medianpos2 <- median(data$Ret_PlusTwo[as.logical(as.numeric(as.character(PosNegcat2)))])
medianneg2 <- median(data$Ret_PlusTwo[-as.logical(as.numeric(as.character(PosNegcat2)))])

```




Classify extreme values
#it looks like Knn is not a good classifier rf is now working but is very slow
```{r}

train_control <- trainControl(method="cv", number=5, verboseIter = TRUE)

class1 <- train(x = data3,y = as.factor(PlusOnecat),  
                preProcess = c("center", "scale"),
                trControl = train_control, 
                tuneLength = 10, method = 'knn' )

preds <- predict(class1, data3)

conf <- confusionMatrix(preds, as.factor(PlusOnecat))

train_control <- trainControl(method="cv", number=10, verboseIter = TRUE)

```


Dealing with time series
```{r}

x <- data %>% select(Ret_121:Ret_180)

#calculates the median of the remaining intraday rates and creates a predictive model
timemeds <- apply(x,1, median)

train_control <- trainControl(method="cv", number=10, repeats = 5, verboseIter = TRUE)

mod1 <- train(y= timemeds, x = datlist2[[1]], method = "lm")

mod2 <- train(y= timemeds[1:100], x = datlist2[[1]], method = "")

timedat <- data %>% select(Ret_2:Ret_160)
imputstime <- amelia(timedat[,1:5], ts = time)
testts <- ts(testzoo)

timedat3 <- timedat %>% t %>% zoo
#percentage missing data, there isnt a lot
sum(is.na(timedat3))/prod(dim(timedat3))

timedat2 <- timedat %>% t
testzoo <- zoo(timedat2) 

#number os missing data points
colSums(is.na(testzoo))


#simple non imputed result
testzoointerp <- na.approx(testzoo)



#number of missing values is now zero
colSums(is.na(testzoointerp))

tsinterpd <- ts(testzoointerp[,3])
tidmod <- ets(tsinterpd)
tidmod <- HoltWinters(tsinterpd, beta=FALSE, gamma=FALSE)
accuracy(tidmod)
forecast(tidmod, 60)

names(forecast(tidmod, 60))

plot(forecast(tidmod, 60))
```

